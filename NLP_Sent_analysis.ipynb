{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d1aeb38",
   "metadata": {},
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8596109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sn\n",
    "from azureml.core import Workspace, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f133bb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "\n",
    "df = pd.read_csv('Dataset/amazonLabelled - amazonLabelled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56f4d510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>Feedback</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I have to jiggle the plug to get it to line up...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S                                           Feedback Sentiment\n",
       "0  1                        Good case, Excellent value.  Positive\n",
       "1  2                             Great for the jawbone.  Positive\n",
       "2  3  Tied to charger for conversations lasting more...  Negative\n",
       "3  4                                  The mic is great.  Positive\n",
       "4  5  I have to jiggle the plug to get it to line up...  Negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8004baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72f341e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a353d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    500\n",
       "Negative    499\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f46ef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b37ce98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4111b64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.fit(df[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20c3d7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Sentiment\"]=lb.transform(df[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85808219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>Feedback</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I have to jiggle the plug to get it to line up...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S                                           Feedback  Sentiment\n",
       "0  1                        Good case, Excellent value.          1\n",
       "1  2                             Great for the jawbone.          1\n",
       "2  3  Tied to charger for conversations lasting more...          0\n",
       "3  4                                  The mic is great.          1\n",
       "4  5  I have to jiggle the plug to get it to line up...          0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f10394e",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fad6a52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a43ef3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(df.drop(\"Sentiment\",axis=1),df[\"Sentiment\"],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b217b310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(799, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8167d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.concat([X_train,y_train],axis=1).to_csv(\"Dataset/train_set.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14384d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.concat([X_test,y_test],axis=1).to_csv(\"Dataset/test_set.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e7be2",
   "metadata": {},
   "source": [
    "# Register dataset to the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2558a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = 'b34c1109-5941-40da-be9e-960b4f30511d'\n",
    "resource_group = 'Learn_MLOps'\n",
    "workspace_name = 'MLOps_WS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b1315fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = Workspace(subscription_id, resource_group, workspace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6941c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the datastore to upload prepared data\n",
    "datastore = workspace.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed65e1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 3 files\n",
      "Uploading Dataset/amazonLabelled - amazonLabelled.csv\n",
      "Uploaded Dataset/amazonLabelled - amazonLabelled.csv, 1 files out of an estimated total of 3\n",
      "Uploading Dataset/test_set.csv\n",
      "Uploaded Dataset/test_set.csv, 2 files out of an estimated total of 3\n",
      "Uploading Dataset/train_set.csv\n",
      "Uploaded Dataset/train_set.csv, 3 files out of an estimated total of 3\n",
      "Uploaded 3 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_d25668d33ec04d86b31d4608fe9967bf"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload the local file from src_dir to the target_path in datastore\n",
    "datastore.upload(src_dir='Dataset', target_path='nlpdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e16d26ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.Tabular.from_delimited_files(datastore.path('nlpdata/train_set.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b3ac953",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Dataset.Tabular.from_delimited_files(datastore.path('nlpdata/test_set.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1751507",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_dataset.register(workspace=workspace,\n",
    "                                 name='nlp_train_set',\n",
    "                                 description='Training data for nlp usecase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d06f72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = test_dataset.register(workspace=workspace,\n",
    "                                 name='nlp_test_set',\n",
    "                                 description='Test data for nlp usecase')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e71df",
   "metadata": {},
   "source": [
    "# Data ingestion step - Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01334770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlp_train_set 1\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.get_by_name(workspace, name='nlp_train_set')\n",
    "print(dataset.name, dataset.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a75efcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "837d5d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>Feedback</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>785</td>\n",
       "      <td>This allows the possibility of double booking ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>908</td>\n",
       "      <td>I can hear while I'm driving in the car, and u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>It has kept up very well.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>862</td>\n",
       "      <td>So far it has worked like a charm.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298</td>\n",
       "      <td>Customer service was terrible.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     S                                           Feedback  Sentiment\n",
       "0  785  This allows the possibility of double booking ...          0\n",
       "1  908  I can hear while I'm driving in the car, and u...          1\n",
       "2   36                          It has kept up very well.          1\n",
       "3  862                 So far it has worked like a charm.          1\n",
       "4  298                     Customer service was terrible.          0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "099c42ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(799, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44367d9",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f40f6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (3.6.2)\n",
      "Requirement already satisfied: tqdm in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (4.61.1)\n",
      "Requirement already satisfied: regex in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (2021.7.6)\n",
      "Requirement already satisfied: click in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (8.0.1)\n",
      "Requirement already satisfied: joblib in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (0.14.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from click->nltk) (4.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->click->nltk) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->click->nltk) (3.10.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41a0a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a8a3ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/azureuser/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ac05c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a65a9ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    corpus=[]\n",
    "    for i in data:\n",
    "        mess=re.sub(\"[^a-zA-Z0-9]\",\" \",i)\n",
    "        mess=mess.lower().split()\n",
    "        mess=[lemmatizer.lemmatize(word) for word in mess if word not in stopwords.words(\"english\")]\n",
    "        mess=\" \".join(mess)\n",
    "        corpus.append(mess)\n",
    "    return corpus    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee001e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=preprocess_data(df[\"Feedback\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa0b750b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "799"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03683925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dfd1d0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b5a5045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2dff6191",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train=cv.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3cc13dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(799, 4436)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431c5745",
   "metadata": {},
   "source": [
    "# Creating experiment and run to log metrics and hypermeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1705c9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "myexperiment = Experiment(workspace, \"rf_sent_analysis\")\n",
    "# initialize a run in Azureml\n",
    "run = myexperiment.start_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b7163d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log(\"dataset name\", dataset.name)\n",
    "run.log(\"dataset Version\", dataset.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32134e51",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "de22529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1de227cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9f5c67fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(count_train,df[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "57625eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9974968710888611"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(count_train,df[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b42e4b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1068fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=cross_val_score(rf,count_train,df[\"Sentiment\"],cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b893dcc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7621628978814076"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "467422ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023789217408980542"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2a805f",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "88eb0431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "06035774",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={'n_estimators': [100, 400,700,1000,2000,2500], 'min_samples_split': [2,4,8,16]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "08d7314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid=GridSearchCV(rf,param_grid,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fedf71fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'min_samples_split': [2, 4, 8, 16],\n",
       "                         'n_estimators': [100, 400, 700, 1000, 2000, 2500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(count_train,df[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "99350b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est=grid.get_params(deep=True)['estimator__n_estimators']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5547b738",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sam_splt=grid.get_params(deep=True)['estimator__min_samples_split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "80689bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(n_estimators=n_est,min_samples_split=min_sam_splt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "301a180b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(count_train,df[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "123cd706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging training parameters to AzureML and MLFlow experiments\n",
    "run.log(\"n_estimators\", grid.get_params(deep=True)['estimator__n_estimators'])\n",
    "run.log(\"min_samples_split\", grid.get_params(deep=True)['estimator__min_samples_split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2ee138b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8136710d",
   "metadata": {},
   "source": [
    "# Model Packaging Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f01e9002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "09712044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outputs/count_vectorizer.pkl']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(cv,\"outputs/count_vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f7245211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outputs/rf_sent_model.pkl']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rf,\"outputs/rf_sent_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4bd64d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210615.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"tutorial-env\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6.2\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-dataset-runtime[pandas,fuse]~=1.32.0\",\n",
       "                        \"numpy\",\n",
       "                        \"joblib\",\n",
       "                        \"azureml-core~=1.32.0\",\n",
       "                        \"azureml-monitoring\",\n",
       "                        \"azureml-defaults~=1.32.0\",\n",
       "                        \"scikit-learn==0.20.3\",\n",
       "                        \"inference-schema[numpy-support]\",\n",
       "                        \"nltk-corpus\",\n",
       "                        \"nltk-stem\"\n",
       "                    ]\n",
       "                },\n",
       "                \"scikit-learn==0.22.1\"\n",
       "            ],\n",
       "            \"name\": \"azureml_8fb3739c3c9bb8a978cadf9c347bc934\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"9\"\n",
       "}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# to install required packages\n",
    "env = Environment('tutorial-env')\n",
    "cd = CondaDependencies.create(pip_packages=['azureml-dataset-runtime[pandas,fuse]', 'azureml-defaults',\"numpy\",  \"joblib\", \"azureml-core\", \"azureml-monitoring\", \"azureml-defaults\", \"scikit-learn==0.20.3\", \"inference-schema\", \"inference-schema[numpy-support]\",\"nltk-corpus\",\"nltk-stem\"], conda_packages = ['scikit-learn==0.22.1'])\n",
    "\n",
    "env.python.conda_dependencies = cd\n",
    "\n",
    "# Register environment to re-use later\n",
    "env.register(workspace = workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eb492e",
   "metadata": {},
   "source": [
    "# Model Registering Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e686fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "65f547b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model NLP_Count_Vectorizer\n",
      "Name: NLP_Count_Vectorizer\n",
      "Version: 1\n"
     ]
    }
   ],
   "source": [
    "# Register Model on AzureML WS\n",
    "model = Model.register(model_path = './outputs/count_vectorizer.pkl', # this points to a local file \n",
    "                       model_name = \"NLP_Count_Vectorizer\", # this is the name the model is registered as\n",
    "                       tags = {'dataset': dataset.name, 'version': dataset.version, }, \n",
    "                       model_framework='pandas==0.23.4',\n",
    "                       description = \"Count Vectorizer\",\n",
    "                       workspace = workspace)\n",
    "\n",
    "print('Name:', model.name)\n",
    "print('Version:', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8e5fc12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model NLP_RF_Model\n",
      "Name: NLP_RF_Model\n",
      "Version: 1\n"
     ]
    }
   ],
   "source": [
    "# Register Model on AzureML WS\n",
    "model = Model.register(model_path = './outputs/rf_sent_model.pkl', # this points to a local file \n",
    "                       model_name = \"NLP_RF_Model\", # this is the name the model is registered as\n",
    "                       tags = {'dataset': dataset.name, 'version': dataset.version, }, \n",
    "                       model_framework='pandas==0.23.4',\n",
    "                       description = \"Random Forest Model\",\n",
    "                       workspace = workspace)\n",
    "\n",
    "print('Name:', model.name)\n",
    "print('Version:', model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dbebaa",
   "metadata": {},
   "source": [
    "# Deploy model as a webservice on Azure Container Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f5ec3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "import time\n",
    "from azureml.core.model import Model\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "def preprocess_data(data):\n",
    "    corpus=[]\n",
    "    for i in data:\n",
    "        mess=re.sub(\"[^a-zA-Z0-9]\",\" \",i)\n",
    "        mess=mess.lower().split()\n",
    "        mess=[lemmatizer.lemmatize(word) for word in mess if word not in stopwords.words(\"english\")]\n",
    "        mess=\" \".join(mess)\n",
    "        corpus.append(mess)\n",
    "    return corpus    \n",
    "\n",
    "\n",
    "def init():\n",
    "    global count_vect,rf_model\n",
    "    \n",
    "    count_vect_path=Model.get_model_path('NLP_Count_Vectorizer')\n",
    "    count_vect= joblib.load(count_vect_path)\n",
    "    \n",
    "    rf_model_path=Model.get_model_path('NLP_RF_Model')\n",
    "    rf_model=joblib.load(rf_model_path)\n",
    "    \n",
    "def run(data):\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    corpus=preprocess_data(data)\n",
    "    count_test=count_vect.transform(corpus)\n",
    "    prediction=rf_model.predict(count_test)\n",
    "    # you can return any data type as long as it is JSON-serializable\n",
    "    return prediction.tolist()\n",
    "                    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3627efd",
   "metadata": {},
   "source": [
    " # Define Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e7001f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dependencies....\n",
      "Registering the environment...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210615.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"MyEnvironment\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6.2\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults~=1.32.0\",\n",
       "                        \"joblib\",\n",
       "                        \"numpy\",\n",
       "                        \"azureml-core~=1.32.0\",\n",
       "                        \"azureml-monitoring\",\n",
       "                        \"inference-schema[numpy-support]\",\n",
       "                        \"nltk\"\n",
       "                    ]\n",
       "                },\n",
       "                \"scikit-learn\",\n",
       "                \"pip\"\n",
       "            ],\n",
       "            \"name\": \"azureml_f69dfa9a9cf30471c4e0b5887a73705b\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"11\"\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.environment import CondaDependencies\n",
    "\n",
    "\n",
    "# Create the environment\n",
    "myenv = Environment(name=\"MyEnvironment\")\n",
    "\n",
    "# Create the dependencies object\n",
    "print(\"Creating dependencies....\")\n",
    "myenv_dep = CondaDependencies.create(conda_packages=['scikit-learn', 'pip'],\n",
    "                                     pip_packages=['azureml-defaults','joblib','numpy','azureml-core', \"azureml-monitoring\", \"inference-schema\", \"inference-schema[numpy-support]\",\"nltk\"])\n",
    "\n",
    "myenv.python.conda_dependencies = myenv_dep\n",
    "\n",
    "# Register the environment\n",
    "print(\"Registering the environment...\")\n",
    "myenv.register(workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b8199c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60a15176",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec44fde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1, collect_model_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08bb1fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(workspace, 'NLP_Count_Vectorizer')\n",
    "model2 = Model(workspace, 'NLP_RF_Model')\n",
    "\n",
    "service_name = 'amazon-feedback-analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d585c6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-08-19 18:00:25+00:00 Creating Container Registry if not exists.\n",
      "2021-08-19 18:00:25+00:00 Registering the environment.\n",
      "2021-08-19 18:00:29+00:00 Building image..\n",
      "2021-08-19 18:07:31+00:00 Generating deployment configuration.\n",
      "2021-08-19 18:07:32+00:00 Submitting deployment to compute..\n",
      "2021-08-19 18:07:35+00:00 Checking the status of deployment amazon-feedback-analysis..\n",
      "2021-08-19 18:12:49+00:00 Checking the status of inference endpoint amazon-feedback-analysis.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "service = Model.deploy(workspace, service_name, models=[model1, model2], inference_config=inference_config, deployment_config=deployment_config, overwrite=True)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d6ee54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afbc83b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5864fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
